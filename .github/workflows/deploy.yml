name: Deploy to AWS

on:
  push:
    branches:
      - main  # Main branch for production deployment (Hetzner)
      - v2  # Legacy branch (kept for compatibility)
      - v2-appearance  # Staging branch (AWS - kept for now)
  workflow_dispatch:

env:
  PYTHON_VERSION: '3.11'

jobs:
  test:
    name: Run Tests
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Free disk space
        run: |
          echo "=== Checking disk space ==="
          df -h
          echo "=== Cleaning up disk space ==="
          # Remove pip cache
          pip cache purge || true
          # Clean system package cache
          sudo apt-get clean || true
          sudo rm -rf /usr/share/dotnet || true
          sudo rm -rf /opt/ghc || true
          sudo rm -rf /usr/local/share/boost || true
          sudo rm -rf "$AGENT_TOOLSDIRECTORY" || true
          # Clean GitHub Actions cache
          sudo rm -rf ~/.cache/pip || true
          sudo rm -rf /tmp/* || true
          echo "=== Disk space after cleanup ==="
          df -h
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          # Install without cache to save disk space
          # Use legacy resolver to handle dependency conflicts (langchain packages)
          pip install --no-cache-dir --use-deprecated=legacy-resolver -r requirements-prod.txt
      
      - name: Run linting
        run: |
          pip install flake8
          # Only lint active codebase files (exclude archive, backups, venv, etc.)
          find . -name "*.py" \
            -not -path "./venv*/*" \
            -not -path "./.git/*" \
            -not -path "./archive/*" \
            -not -path "./backups/*" \
            -not -path "./__pycache__/*" \
            -not -path "./chroma_db/*" \
            -not -path "./uploads/*" \
            -not -path "./data/*" \
            -not -path "./logs/*" \
            -not -path "./*.pyc" | xargs flake8 --count --select=E9,F63,F7,F82 --show-source --statistics || true
          find . -name "*.py" \
            -not -path "./venv*/*" \
            -not -path "./.git/*" \
            -not -path "./archive/*" \
            -not -path "./backups/*" \
            -not -path "./__pycache__/*" \
            -not -path "./chroma_db/*" \
            -not -path "./uploads/*" \
            -not -path "./data/*" \
            -not -path "./logs/*" \
            -not -path "./*.pyc" | xargs flake8 --count --exit-zero --max-complexity=10 --max-line-length=127 --statistics || true
      
      - name: Check for syntax errors
        run: |
          python -m py_compile app.py
          # Only check active code, exclude archive, backups, venv, etc.
          find . -name "*.py" \
            -not -path "./venv*/*" \
            -not -path "./.git/*" \
            -not -path "./archive/*" \
            -not -path "./backups/*" \
            -not -path "./__pycache__/*" \
            -not -path "./chroma_db/*" \
            -not -path "./uploads/*" \
            -exec python -m py_compile {} \;
      
      - name: Verify imports
        run: |
          # Set dummy API key for import tests (actual key not needed for import verification)
          export OPENAI_API_KEY="test-key-for-import-only" || true
          python -c "import app; print('✅ App imports successfully')"
          python -c "from blueprints import register_blueprints; print('✅ Blueprints import successfully')"
          python -c "from services import chatbot_service; print('✅ Services import successfully')"
      
      - name: Cleanup after tests
        if: always()
        run: |
          echo "=== Final cleanup ==="
          pip cache purge || true
          sudo apt-get clean || true
          rm -rf __pycache__ || true
          find . -type d -name __pycache__ -exec rm -rf {} + || true
          echo "=== Final disk space ==="
          df -h

  deploy-production:
    name: Deploy to Production
    needs: test
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main' || github.ref == 'refs/heads/v2' || github.ref == 'refs/heads/v2-appearance'
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Configure SSH
        run: |
          mkdir -p ~/.ssh
          # Configure AWS SSH (for v2-appearance branch)
          if [ "${{ github.ref }}" == "refs/heads/v2-appearance" ] || [ "${{ github.ref }}" == "refs/heads/v2" ]; then
            echo "${{ secrets.AWS_SSH_PRIVATE_KEY }}" > ~/.ssh/deploy_key
            chmod 600 ~/.ssh/deploy_key
            ssh-keyscan -H ${{ secrets.AWS_EC2_HOST }} >> ~/.ssh/known_hosts
          fi
          # Configure Hetzner SSH (for main branch)
          if [ "${{ github.ref }}" == "refs/heads/main" ]; then
            echo "${{ secrets.HETZNER_SSH_PRIVATE_KEY }}" > ~/.ssh/hetzner_key
            chmod 600 ~/.ssh/hetzner_key
            ssh-keyscan -H ${{ secrets.HETZNER_HOST }} >> ~/.ssh/known_hosts
          fi
      
      - name: Create deployment script
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          cat > deploy.sh << 'DEPLOYSCRIPT'
          #!/bin/bash
          set -e
          
          DEPLOY_PATH="$1"
          REPO_URL="$2"
          GITHUB_TOKEN="$3"
          APP_NAME="$4"
          APP_PORT="$5"
          
          echo "=== Starting Production Deployment ==="
          
          # Determine branch from GITHUB_REF environment variable
          if [ -n "$GITHUB_REF" ]; then
            BRANCH_NAME=$(echo "$GITHUB_REF" | sed 's|refs/heads/||')
          else
            BRANCH_NAME="main"
          fi
          
          echo "=== Deploying branch: $BRANCH_NAME ==="
          
          echo "=== Pulling latest code ==="
          if [ -d "$DEPLOY_PATH/.git" ]; then
            echo "Git repository found, pulling latest changes..."
            cd "$DEPLOY_PATH"
            
            # Configure git credential helper for token authentication
            if [ -n "$GITHUB_TOKEN" ]; then
              git config --local credential.helper store
              echo "https://${GITHUB_TOKEN}@github.com" > ~/.git-credentials
              git remote set-url origin "$REPO_URL"
            fi
            
            # Try to fetch
            if git fetch origin 2>/dev/null; then
              echo "Fetch successful, resetting to origin/$BRANCH_NAME..."
              git reset --hard "origin/$BRANCH_NAME"
              git clean -fd
            else
              echo "Fetch failed, trying GitHub API tarball download..."
              cd /tmp
              TEMP_DIR=$(mktemp -d)
              cd "$TEMP_DIR"
              
              # Use GitHub API to download tarball (more reliable than git clone with token)
              REPO_NAME=$(echo "$REPO_URL" | sed 's|https://github.com/||; s|\.git$||')
              if [ -n "$GITHUB_TOKEN" ]; then
                curl -L -H "Authorization: token ${GITHUB_TOKEN}" \
                  -H "Accept: application/vnd.github.v3.raw" \
                  "https://api.github.com/repos/${REPO_NAME}/tarball/${BRANCH_NAME}" \
                  -o repo.tar.gz
              else
                curl -L "https://api.github.com/repos/${REPO_NAME}/tarball/${BRANCH_NAME}" \
                  -o repo.tar.gz
              fi
              
              if [ -f repo.tar.gz ]; then
                tar -xzf repo.tar.gz
                REPO_DIR=$(ls -d */ | head -1)
                rsync -av --exclude='.git' --exclude='venv*' --exclude='__pycache__' --exclude='*.pyc' --exclude='instance' --exclude='.env' --exclude='chroma_db' --exclude='uploads' --exclude='*.db' --exclude='*.sqlite*' "$REPO_DIR" "$DEPLOY_PATH/"
                rm -rf "$TEMP_DIR"
                cd "$DEPLOY_PATH"
              else
                echo "Failed to download tarball, trying git clone with token in URL..."
                if [ -n "$GITHUB_TOKEN" ]; then
                  git clone "https://${GITHUB_TOKEN}@github.com/${REPO_NAME}.git" temp-repo
                  cd temp-repo
                  git checkout "$BRANCH_NAME"
                  rsync -av --exclude='.git' --exclude='venv*' --exclude='__pycache__' --exclude='*.pyc' --exclude='instance' --exclude='.env' --exclude='chroma_db' --exclude='uploads' --exclude='*.db' --exclude='*.sqlite*' ./ "$DEPLOY_PATH/"
                  cd /tmp
                  rm -rf "$TEMP_DIR"
                  cd "$DEPLOY_PATH"
                else
                  echo "No token available, cannot clone"
                  exit 1
                fi
              fi
            fi
          else
            echo "Not a git repository, downloading via GitHub API tarball..."
            cd /tmp
            TEMP_DIR=$(mktemp -d)
            cd "$TEMP_DIR"
            
            # Use GitHub API to download tarball (most reliable method)
            REPO_NAME=$(echo "$REPO_URL" | sed 's|https://github.com/||; s|\.git$||')
            echo "Downloading ${REPO_NAME} branch ${BRANCH_NAME}..."
            
            if [ -n "$GITHUB_TOKEN" ]; then
              curl -L -H "Authorization: token ${GITHUB_TOKEN}" \
                -H "Accept: application/vnd.github.v3.raw" \
                "https://api.github.com/repos/${REPO_NAME}/tarball/${BRANCH_NAME}" \
                -o repo.tar.gz
            else
              curl -L "https://api.github.com/repos/${REPO_NAME}/tarball/${BRANCH_NAME}" \
                -o repo.tar.gz
            fi
            
            if [ -f repo.tar.gz ] && [ -s repo.tar.gz ]; then
              echo "Tarball downloaded successfully, extracting..."
              tar -xzf repo.tar.gz
              REPO_DIR=$(ls -d */ | head -1)
              echo "Syncing files to $DEPLOY_PATH..."
              rsync -av --exclude='.git' --exclude='venv*' --exclude='__pycache__' --exclude='*.pyc' --exclude='instance' --exclude='.env' --exclude='chroma_db' --exclude='uploads' --exclude='*.db' --exclude='*.sqlite*' "$REPO_DIR" "$DEPLOY_PATH/"
              rm -rf "$TEMP_DIR"
              cd "$DEPLOY_PATH"
              echo "Code deployed successfully"
            else
              echo "Tarball download failed, trying git clone as last resort..."
              if [ -n "$GITHUB_TOKEN" ]; then
                # Use GIT_ASKPASS to avoid password prompt
                export GIT_ASKPASS=echo
                export GIT_TERMINAL_PROMPT=0
                git clone "https://${GITHUB_TOKEN}@github.com/${REPO_NAME}.git" temp-repo
                cd temp-repo
                git checkout "$BRANCH_NAME"
                rsync -av --exclude='.git' --exclude='venv*' --exclude='__pycache__' --exclude='*.pyc' --exclude='instance' --exclude='.env' --exclude='chroma_db' --exclude='uploads' --exclude='*.db' --exclude='*.sqlite*' ./ "$DEPLOY_PATH/"
                cd /tmp
                rm -rf "$TEMP_DIR"
                cd "$DEPLOY_PATH"
              else
                echo "No token available and tarball failed, cannot deploy"
                exit 1
              fi
            fi
          fi
          
          echo "=== Activating virtual environment ==="
          if [ ! -d "venv-prod" ]; then
            python3 -m venv venv-prod
          fi
          source venv-prod/bin/activate
          
          echo "=== Cleaning up disk space ==="
          # Clean pip cache
          pip cache purge || true
          # Remove old venv if exists (might have heavy packages)
          if [ -d "venv" ]; then
            echo "Removing old venv directory..."
            rm -rf venv
          fi
          # Clean system package cache
          sudo apt-get clean || true
          # Check disk space
          df -h / || true
          
          echo "=== Installing/updating dependencies ==="
          pip install --upgrade pip
          # Use requirements-prod.txt (optimized, no heavy dependencies)
          if [ -f "requirements-prod.txt" ]; then
            echo "Installing from requirements-prod.txt (optimized - no torch, no CUDA)"
            # Install without cache to save disk space
            # Use legacy resolver to handle dependency conflicts (langchain packages)
            pip install --no-cache-dir --use-deprecated=legacy-resolver -r requirements-prod.txt
          else
            echo "ERROR: requirements-prod.txt not found!"
            exit 1
          fi
          
          echo "=== Cleaning up old dependencies ==="
          # Remove old venv if it exists and has heavy packages
          if [ -d "venv" ]; then
            echo "Removing old venv directory to free space..."
            rm -rf venv
          fi
          
          echo "=== Creating necessary directories ==="
          mkdir -p uploads chroma_db config logs data
          
          echo "=== Restarting application ==="
          if screen -list | grep -q "$APP_NAME"; then
            screen -S "$APP_NAME" -X quit || true
            sleep 2
          fi
          
          screen -dmS "$APP_NAME" bash -c "cd '$DEPLOY_PATH' && source venv-prod/bin/activate && python app.py"
          
          echo "=== Waiting for services to start ==="
          sleep 5
          
          echo "=== Checking application status ==="
          screen -list
          
          echo "=== Testing health endpoint ==="
          sleep 3
          curl -f http://localhost:$APP_PORT/health || echo "Health check failed, but app may still be starting"
          
          echo "=== Deployment completed ==="
          DEPLOYSCRIPT
          chmod +x deploy.sh
      
      - name: Deploy to AWS EC2 (v2-appearance branch)
        if: github.ref == 'refs/heads/v2-appearance'
        env:
          REPO_URL: https://github.com/${{ github.repository }}.git
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          APP_NAME: cortex-app
          APP_PORT: ${{ secrets.AWS_APP_PORT || '6002' }}
          GITHUB_REF: ${{ github.ref }}
        run: |
          scp -i ~/.ssh/deploy_key -o StrictHostKeyChecking=no deploy.sh ${{ secrets.AWS_EC2_USER }}@${{ secrets.AWS_EC2_HOST }}:/tmp/deploy.sh
          ssh -i ~/.ssh/deploy_key -o StrictHostKeyChecking=no ${{ secrets.AWS_EC2_USER }}@${{ secrets.AWS_EC2_HOST }} "export GITHUB_REF='$GITHUB_REF' && bash /tmp/deploy.sh ${{ secrets.AWS_DEPLOY_PATH }} '$REPO_URL' '$GITHUB_TOKEN' '$APP_NAME' '$APP_PORT'"
      
      - name: Deploy to Hetzner Kubernetes (main branch)
        if: github.ref == 'refs/heads/main'
        env:
          REPO_URL: https://github.com/${{ github.repository }}.git
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          GITHUB_REF: ${{ github.ref }}
        run: |
          echo "=== Deploying to Hetzner Kubernetes ==="
          
          mkdir -p ~/.ssh
          echo "${{ secrets.HETZNER_SSH_PRIVATE_KEY }}" > ~/.ssh/hetzner_key
          chmod 600 ~/.ssh/hetzner_key
          ssh-keyscan -H ${{ secrets.HETZNER_HOST }} >> ~/.ssh/known_hosts
          
          # Configure SSH for long-running connections
          SSH_OPTS="-i ~/.ssh/hetzner_key -o StrictHostKeyChecking=no -o ServerAliveInterval=60 -o ServerAliveCountMax=3 -o ConnectTimeout=30"
          
          # Upload source code to Hetzner and build there (avoids GitHub Actions disk space issues)
          echo "=== Uploading source code to Hetzner ==="
          tar --exclude='.git' --exclude='venv' --exclude='__pycache__' --exclude='*.pyc' --exclude='.env' --exclude='chroma_db' --exclude='uploads' --exclude='*.db' --exclude='*.sqlite*' --exclude='logs' --exclude='data' -czf /tmp/cortex-source.tar.gz .
          scp $SSH_OPTS /tmp/cortex-source.tar.gz root@${{ secrets.HETZNER_HOST }}:/tmp/
          rm -f /tmp/cortex-source.tar.gz
          
          # Build Docker image directly on Hetzner server
          echo "=== Building Docker image on Hetzner ==="
          ssh $SSH_OPTS root@${{ secrets.HETZNER_HOST }} << 'DEPLOY_SCRIPT'
            set -e
            set -o pipefail
            
            echo "=== Checking disk space before cleanup ==="
            df -h
            
            echo "=== Cleaning up disk space ==="
            # Remove old Docker images (except cortex:latest)
            docker images --format "{{.Repository}}:{{.Tag}}" | grep -v "REPOSITORY" | grep -v "cortex:latest" | while read img; do
              if [ -n "$img" ]; then
                echo "Removing old Docker image: $img"
                docker rmi "$img" 2>/dev/null || true
              fi
            done || true
            
            # Prune Docker system
            docker system prune -af --volumes || true
            
            # Clean up old k3s images (except cortex)
            k3s ctr images ls 2>/dev/null | grep -v "cortex" | awk '{print $1}' | while read img; do
              if [ -n "$img" ] && [ "$img" != "IMAGE" ] && [ "$img" != "docker.io/library" ]; then
                echo "Removing old k3s image: $img"
                k3s ctr images rm "$img" 2>/dev/null || true
              fi
            done || true
            
            # Clean up old build artifacts
            rm -rf /tmp/cortex-build* || true
            rm -rf /tmp/cortex-source.tar.gz || true
            
            echo "=== Disk space after cleanup ==="
            df -h
            
            cd /tmp
            rm -rf cortex-build || true
            mkdir -p cortex-build
            cd cortex-build
            tar -xzf /tmp/cortex-source.tar.gz
            rm /tmp/cortex-source.tar.gz
            
            echo "Building Docker image (this may take several minutes)..."
            # Retry logic for Docker build (handles transient network issues)
            MAX_RETRIES=3
            RETRY_COUNT=0
            BUILD_SUCCESS=false
            
            while [ $RETRY_COUNT -lt $MAX_RETRIES ]; do
              if docker build -t cortex:latest .; then
                BUILD_SUCCESS=true
                break
              else
                RETRY_COUNT=$((RETRY_COUNT + 1))
                if [ $RETRY_COUNT -lt $MAX_RETRIES ]; then
                  echo "⚠️ Docker build failed, retrying ($RETRY_COUNT/$MAX_RETRIES)..."
                  sleep 10
                else
                  echo "❌ Docker build failed after $MAX_RETRIES attempts"
                  exit 1
                fi
              fi
            done
            
            echo "Importing image into k3s..."
            docker save cortex:latest | k3s ctr images import - || {
              echo "❌ Image import failed"
              exit 1
            }
            
            echo "Applying deployment with persistence configuration..."
            if [ -f k8s/deployment.yaml ]; then
              kubectl apply -f k8s/deployment.yaml || {
                echo "⚠️ Deployment apply failed, trying rollout restart instead"
                kubectl rollout restart deployment/cortex-app -n cortex || {
                  echo "❌ Deployment restart failed"
                  exit 1
                }
              }
            else
              echo "⚠️ k8s/deployment.yaml not found, using rollout restart"
              kubectl rollout restart deployment/cortex-app -n cortex || {
                echo "❌ Deployment restart failed"
                exit 1
              }
            fi
            
            kubectl rollout status deployment/cortex-app -n cortex --timeout=120s || {
              echo "⚠️ Deployment status check timed out, but may still be in progress"
            }
            
            echo "Verifying persistence mounts..."
            POD=$(kubectl get pods -n cortex -l app=cortex -o jsonpath='{.items[0].metadata.name}' 2>/dev/null || echo "")
            if [ -n "$POD" ]; then
              echo "Pod: $POD"
              echo "Volume mounts:"
              kubectl get pod "$POD" -n cortex -o jsonpath='{.spec.containers[0].volumeMounts[*].mountPath}' 2>/dev/null | tr ' ' '\n' || echo "Could not verify mounts"
            fi
            
            echo "Cleaning up..."
            cd /
            rm -rf /tmp/cortex-build
            
            echo "✅ Deployment complete"
          DEPLOY_SCRIPT
      
      - name: Verify deployment
        run: |
          sleep 10
          if [ "${{ github.ref }}" == "refs/heads/main" ]; then
            curl -f ${{ secrets.HETZNER_APP_URL || 'https://cortex.janisrael.com' }}/health || echo "Health check failed, but deployment may still be in progress"
          else
            curl -f ${{ secrets.AWS_APP_URL || 'https://cortex.janisrael.com' }}/health || echo "Health check failed, but deployment may still be in progress"
          fi
      
      - name: Notify deployment status
        if: always()
        run: |
          if [ "${{ job.status }}" == "success" ]; then
            echo "✅ Production deployment successful!"
          else
            echo "❌ Production deployment failed!"
          fi


